#!/usr/bin/env python3
"""
üöÄ ULTRA-FAST MODE - 40% FASTER!
Skip table detection for maximum speed
12 hours ‚Üí 7 hours (or 3 hours ‚Üí 1.8 hours with parallel)
"""
import json
import sys
from pathlib import Path
from datetime import datetime

CHAPTERS = {
    1: {"name": "Descripci√≥n de la Perturbaci√≥n", "pages": (1, 11)},
    2: {"name": "Equipamiento Afectado", "pages": (12, 90)},
    3: {"name": "Energ√≠a No Suministrada", "pages": (91, 153)},
    4: {"name": "Configuraciones de Falla", "pages": (154, 159)},
    5: {"name": "Cronolog√≠a de Eventos", "pages": (160, 171)},
    6: {"name": "Normalizaci√≥n del Servicio", "pages": (172, 265)},
    7: {"name": "An√°lisis de Causas de Falla", "pages": (266, 347)},
    8: {"name": "Detalle de Informaci√≥n", "pages": (348, 348)},
    9: {"name": "An√°lisis de Protecciones", "pages": (349, 381)},
    10: {"name": "Pronunciamiento T√©cnico", "pages": (382, 392)},
    11: {"name": "Recomendaciones", "pages": (393, 399)},
}

BASE_DIR = Path(__file__).parent
project_root = BASE_DIR.parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import (
    PdfPipelineOptions,
    AcceleratorOptions
)

print("=" * 80)
print("üöÄ ULTRA-FAST MODE - NO TABLE DETECTION")
print("=" * 80)
print("‚ö†Ô∏è  WARNING: Table structure will NOT be detected")
print("‚úÖ BENEFIT: 40% faster processing")
print()
print("üìä Best for: Documents where you only need text/headers")
print("‚ùå Not for: Documents with complex tables")
print()

def extract_chapter_ultrafast(chapter_num, chapter_info):
    """Extract with ultra-fast settings - NO table detection"""
    chapter_name = chapter_info["name"]
    start_page, end_page = chapter_info["pages"]

    print(f"üìñ Chapter {chapter_num}: {chapter_name} (pages {start_page}-{end_page})")

    # Setup output directory
    output_dir = BASE_DIR / f"capitulo_{chapter_num:02d}"
    output_dir.mkdir(parents=True, exist_ok=True)
    outputs_dir = output_dir / "outputs"
    outputs_dir.mkdir(exist_ok=True)

    json_path = outputs_dir / "layout_ultrafast.json"

    if json_path.exists():
        print(f"   ‚è≠Ô∏è  Already processed")
        print()
        return True

    pdf_path = project_root / "domains" / "operaciones" / "eaf" / "shared" / "source" / "EAF-089-2025.pdf"

    # ULTRA-FAST CONFIG - Minimal features
    print(f"   üîß Configuring ULTRA-FAST mode...")
    pipeline_options = PdfPipelineOptions(
        accelerator_options=AcceleratorOptions(
            num_threads=4,
            device="cuda",
        ),
        # ALL heavy features OFF
        do_ocr=False,
        do_picture_classification=False,
        do_picture_description=False,
        do_code_enrichment=False,
        do_formula_enrichment=False,
        do_table_structure=False,  # ‚Üê KEY: Skip table detection!
        generate_page_images=False,
        generate_picture_images=False,
        generate_table_images=False,
    )

    format_options = {
        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
    }

    converter = DocumentConverter(format_options=format_options)

    # Convert
    print(f"   üîç Converting (FAST)...")
    result = converter.convert(str(pdf_path))

    # Extract elements
    print(f"   üìä Extracting elements...")
    chapter_elements = []

    for item in result.document.iterate_items():
        if isinstance(item, tuple):
            item, level = item

        if not hasattr(item, 'prov') or not item.prov:
            continue

        for prov in item.prov:
            if start_page <= prov.page_no <= end_page:
                if prov.page_no not in result.document.pages:
                    continue

                page = result.document.pages[prov.page_no]
                bbox = prov.bbox
                bbox_tl = bbox.to_top_left_origin(page_height=page.size.height)
                bbox_norm = bbox.normalized(page.size)

                if hasattr(item, 'text'):
                    text_content = item.text if item.text else ""
                elif hasattr(item, 'export_to_markdown'):
                    text_content = item.export_to_markdown()
                else:
                    text_content = str(item) if item else ""

                element = {
                    "type": item.label,
                    "text": text_content,
                    "page": prov.page_no,
                    "bbox": {
                        "x0": round(bbox_tl.l, 2),
                        "y0": round(bbox_tl.t, 2),
                        "x1": round(bbox_tl.r, 2),
                        "y1": round(bbox_tl.b, 2)
                    },
                    "bbox_normalized": {
                        "x0": round(bbox_norm.l, 4),
                        "y0": round(bbox_norm.t, 4),
                        "x1": round(bbox_norm.r, 4),
                        "y1": round(bbox_norm.b, 4)
                    },
                    "page_dimensions": {
                        "width": page.size.width,
                        "height": page.size.height
                    }
                }
                chapter_elements.append(element)

    # Save JSON
    data = {
        "metadata": {
            "chapter": f"Cap√≠tulo {chapter_num} - {chapter_name}",
            "pdf_source": str(pdf_path),
            "extraction_date": datetime.now().isoformat(),
            "extractor": "Docling ULTRA-FAST (No table detection)",
            "total_elements": len(chapter_elements),
            "pages": f"{start_page}-{end_page}",
            "mode": "ultrafast",
            "features_disabled": [
                "Table structure detection",
                "OCR",
                "Image classification",
                "Picture description",
                "Code enrichment",
                "Formula enrichment"
            ]
        },
        "elements": chapter_elements
    }

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"   ‚úÖ Extracted {len(chapter_elements)} elements")
    print(f"   üíæ Saved: layout_ultrafast.json")
    print()

    return True

# Process all chapters
print("üîÑ Starting ULTRA-FAST processing...")
print()

success_count = 0
for chapter_num, chapter_info in CHAPTERS.items():
    try:
        if extract_chapter_ultrafast(chapter_num, chapter_info):
            success_count += 1
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        print()
        continue

print("=" * 80)
print("‚úÖ ULTRA-FAST PROCESSING COMPLETE")
print("=" * 80)
print(f"üìä Processed: {success_count}/{len(CHAPTERS)} chapters")
print()
print("‚ö†Ô∏è  REMINDER: Table structure was NOT detected")
print("üí° If you need tables, use FAST_process_parallel.py instead")
print()
